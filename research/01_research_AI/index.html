<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Artificial Intelligence for Inclusive and Digital Humanities | Digital Arena for Inclusive Humanities (DAIH) </title> <meta name="description" content="The Digital Arena for Inclusive Humanities (DAIH) is an interdisciplinary research center of excellence in the field of digital technologies and computational methods applied to languages and literature, with a focus on inclusion."> <meta name="keywords" content="artificial intelligence, computer science, digital humanities, inclusion, diversity, equity, computational methods, digital technologies, natural language processing, literary studies, linguistic studies, digital scholarly edition"> <meta property="og:site_name" content="Digital Arena for Inclusive Humanities (DAIH)"> <meta property="og:type" content="website"> <meta property="og:title" content="Digital Arena for Inclusive Humanities (DAIH) | Artificial Intelligence for Inclusive and Digital Humanities"> <meta property="og:url" content="https://daih.eu/research/01_research_AI/"> <meta property="og:description" content="The Digital Arena for Inclusive Humanities (DAIH) is an interdisciplinary research center of excellence in the field of digital technologies and computational methods applied to languages and literature, with a focus on inclusion."> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="Artificial Intelligence for Inclusive and Digital Humanities"> <meta name="twitter:description" content="The Digital Arena for Inclusive Humanities (DAIH) is an interdisciplinary research center of excellence in the field of digital technologies and computational methods applied to languages and literature, with a focus on inclusion."> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": " "
        },
        "url": "https://daih.eu/research/01_research_AI/",
        "@type": "WebSite",
        "description": "The Digital Arena for Inclusive Humanities (DAIH) is an interdisciplinary research center of excellence in the field of digital technologies and computational methods applied to languages and literature, with a focus on inclusion.",
        "headline": "Artificial Intelligence for Inclusive and Digital Humanities",
        
        "sameAs": ["https://github.com/daih-univr"],
        
        "name": " ",
        "@context": "https://schema.org"
    }
  </script> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico?379bc0ae4431f529129ed44db4f28c4e"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://daih.eu/research/01_research_AI/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-md fixed-top" role="navigation"> <div class="container"> <div style="padding-top: 10px"> <a href="/" class=""> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/daih_logo-480.webp 480w,/assets/img/daih_logo-800.webp 800w,/assets/img/daih_logo-1400.webp 1400w," sizes="(min-width: 1000px) 125px, (min-width: 576px) 125px, 125px" type="image/webp"> <img src="/assets/img/daih_logo.png?0032d612f7184e1f8154ee1459a4f824" width="100%" height="auto" alt="Digital Arena for Inclusive Humanities (DAIH)" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item active"> <a class="nav-link" href="/research/">research <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/network/">network </a> </li> <li class="nav-item "> <a class="nav-link" href="/events/">events </a> </li> <li class="nav-item "> <a class="nav-link" href="/collaborate/">collaborate </a> </li> <li class="nav-item "> <a class="nav-link" href="/contact/">contact </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Artificial Intelligence for Inclusive and Digital Humanities</h1> <p class="post-description"></p> </header> <article> <p>We at DAIH delve into the advancement of Artificial Intelligence (AI) methodologies, techniques, and tools, focusing, among others, on their application to Digital Humanities (e.g., <a class="citation" href="#2021ijdl">(Lorenzini et al., 2021)</a>) and particularly those pertaining to languages and literatures. Our primary research streams encompass the development of tools and techniques for:</p> <ul> <li>Natural language processing and the extraction of high-quality knowledge from textual resources (e.g., <a class="citation" href="#2023cbm">(Bombieri et al., 2023; Rospocher, 2021; Rospocher &amp; Corcoglioniti, 2020)</a>);</li> <li>The establishment of robust representations of extracted knowledge and automated reasoning for deriving new insights (e.g., <a class="citation" href="#2016tkde">(Corcoglioniti et al., 2016; Rospocher et al., 2016)</a>);</li> <li>Developing resources and applications in accordance with Semantic Web and Linked Data best practices (e.g., <a class="citation" href="#2019lre">(Rospocher et al., 2019)</a>);</li> <li>Facilitating effective information and document retrieval (e.g., <a class="citation" href="#2019swj">(Rospocher et al., 2019)</a>).</li> </ul> <p>Furthermore, we explore the influence of Artificial Intelligence (AI) and Natural Language Processing (NLP) on diversity, equity, and inclusion, an area of growing importance in contemporary computer science and artificial intelligence research. On one hand, we aim to scrutinize the potential challenges that artificial intelligence techniques may introduce or exacerbate in terms of inclusion. This involves an examination of issues and social biases (such as those pertaining to gender, race, religion, or disabilities) present in computational models trained on huge datasets. Conversely, we seek the development and implementation of concrete tools, methods, technologies, and computational models for automating tasks that foster inclusion and enhance content accessibility.</p> <p>Moreover, we are also dedicated to analyzing biases towards Artificial Intelligence. For instance, we study the reactions and perceptions of readers towards narratives authored by generative Artificial Intelligence language models. This exploration seeks to comprehend how readers assess such texts in terms of likability, emotional resonance, artistic merit, and inclusivity.</p> </article> <h2 style="padding-top: 20px">References</h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div id="2021ijdl" class="col-sm-12"> <div class="title"><a href="https://doi.org/10.1007/s00799-021-00302-1" rel="external nofollow noopener" target="_blank">Automatically evaluating the quality of textual descriptions in cultural heritage records</a></div> <div class="author"> Matteo Lorenzini, Marco Rospocher, Sara Tonelli </div> <div class="periodical"> <em>International Journal on Digital Libraries</em>, 2021 </div> <div class="periodical"> </div> <div class="abstract hidden"> <p>Metadata are fundamental for the indexing, browsing and retrieval of cultural heritage resources in repositories, digital libraries and catalogues. In order to be effectively exploited, metadata information has to meet some quality standards, typically defined in the collection usage guidelines. As manually checking the quality of metadata in a repository may not be affordable, especially in large collections, in this paper we specifically address the problem of automatically assessing the quality of metadata, focusing in particular on textual descriptions of cultural heritage items. We describe a novel approach based on machine learning that tackles this problem by framing it as a binary text classification task aimed at evaluating the accuracy of textual descriptions. We report our assessment of different classifiers using a new dataset that we developed, containing more than 100K descriptions. The dataset was extracted from different collections and domains from the Italian digital library “Cultura Italia”and was annotated with accuracy information in terms of compliance with the cataloguing guidelines. The results empirically confirm that our proposed approach can effectively support curators (F1  0.85) in assessing the quality of the textual descriptions of the records in their collections and provide some insights into how training data, specifically their size and domain, can affect classification performance.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="2023cbm" class="col-sm-12"> <div class="title"><a href="https://www.sciencedirect.com/science/article/pii/S0010482522011234" rel="external nofollow noopener" target="_blank">Machine understanding surgical actions from intervention procedure textbooks</a></div> <div class="author"> Marco Bombieri, Marco Rospocher, Simone Paolo Ponzetto, Paolo Fiorini </div> <div class="periodical"> <em>Computers in Biology and Medicine</em>, 2023 </div> <div class="periodical"> </div> <div class="abstract hidden"> <p>The automatic extraction of procedural surgical knowledge from surgery manuals, academic papers or other high-quality textual resources, is of the utmost importance to develop knowledge-based clinical decision support systems, to automatically execute some procedure’s step or to summarize the procedural information, spread throughout the texts, in a structured form usable as a study resource by medical students. In this work, we propose a first benchmark on extracting detailed surgical actions from available intervention procedure textbooks and papers. We frame the problem as a Semantic Role Labeling task. Exploiting a manually annotated dataset, we apply different Transformer-based information extraction methods. Starting from RoBERTa and BioMedRoBERTa pre-trained language models, we first investigate a zero-shot scenario and compare the obtained results with a full fine-tuning setting. We then introduce a new ad-hoc surgical language model, named SurgicBERTa, pre-trained on a large collection of surgical materials, and we compare it with the previous ones. In the assessment, we explore different dataset splits (one in-domain and two out-of-domain) and we investigate also the effectiveness of the approach in a few-shot learning scenario. Performance are evaluated on three correlated sub-tasks: predicate disambiguation, semantic argument disambiguation and predicate-argument disambiguation. Results show that the fine-tuning of a pre-trained domain-specific language model achieves the highest performance on all splits and on all sub-tasks. All models are publicly released.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="2021eswa" class="col-sm-12"> <div class="title"><a href="http://www.sciencedirect.com/science/article/pii/S095741742030573X" rel="external nofollow noopener" target="_blank">Explicit song lyrics detection with subword-enriched word embeddings</a></div> <div class="author"> Marco Rospocher </div> <div class="periodical"> <em>Expert Systems with Applications</em>, 2021 </div> <div class="periodical"> </div> <div class="abstract hidden"> <p>In this paper, we investigate the problem of automatically detecting explicit song lyrics, i.e., determining if the lyrics of a given song could be offensive or unsuitable for children. The problem can be framed as a binary classification task, and in this work we propose to tackle it with the fastText classifier, an efficient linear classification model leveraging a peculiar distributional text representation that, by exploiting subword information in building the embeddings of the words, enables to cope with words not seen at training time. We assess the performance of the fastText classifier and word representations with a lyrics dataset of over 800K songs, annotated with explicit information, that we assembled from publicly available resources. The evaluation shows that the fastText classifier is effective for explicit lyrics detection, substantially outperforming a reference approach for the task, and that the subword information effectively contributes to this result.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="2020jws" class="col-sm-12"> <div class="title"><a href="http://www.sciencedirect.com/science/article/pii/S1570826820300500" rel="external nofollow noopener" target="_blank">Knowledge-driven joint posterior revision of named entity classification and linking</a></div> <div class="author"> Marco Rospocher, Francesco Corcoglioniti </div> <div class="periodical"> <em>Journal of Web Semantics</em>, 2020 </div> <div class="periodical"> </div> <div class="abstract hidden"> <p>In this work we address the problem of extracting quality entity knowledge from natural language text, an important task for the automatic construction of knowledge graphs from unstructured content. More in details, we investigate the benefit of performing a joint posterior revision, driven by ontological background knowledge, of the annotations resulting from natural language processing (NLP) entity analyses such as named entity recognition and classification (NERC) and entity linking (EL). The revision is performed via a probabilistic model, called jpark, that given the candidate annotations independently identified by NERC and EL tools on the same textual entity mention, reconsiders the best annotation choice performed by the tools in light of the coherence of the candidate annotations with the ontological knowledge. The model can be explicitly instructed to handle the information that an entity can potentially be NIL (i.e., lacking a corresponding referent in the target linking knowledge base), exploiting it for predicting the best NERC and EL annotation combination. We present a comprehensive evaluation of jpark along various dimensions, comparing its performances with and without exploiting NIL information, as well as the usage of three different background knowledge resources (YAGO, DBpedia, and Wikidata) to build the model. The evaluation, conducted using different tools (the popular Stanford NER and DBpedia Spotlight, as well as the more recent Flair NER and End-to-End Neural EL) with three reference datasets (AIDA, MEANTIME, and TAC-KBP), empirically confirms the capability of the model to improve the quality of the annotations of the given tools, and thus their performances on the tasks they are designed for.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="2016tkde" class="col-sm-12"> <div class="title"><a href="https://ieeexplore.ieee.org/document/7549111/" rel="external nofollow noopener" target="_blank">Frame-Based Ontology Population with PIKES</a></div> <div class="author"> Francesco Corcoglioniti, Marco Rospocher, Alessio Palmero Aprosio </div> <div class="periodical"> <em>IEEE Transactions on Knowledge and Data Engineering</em>, 2016 </div> <div class="periodical"> </div> <div class="abstract hidden"> <p>We present an approach for ontology population from natural language English texts that extracts RDF triples according to FrameBase, a Semantic Web ontology derived from FrameNet. Processing is decoupled in two independently-tunable phases. First, text is processed by several NLP tasks, including Semantic Role Labeling (SRL), whose results are integrated in an RDF graph of mentions, i.e., snippets of text denoting some entity/fact. Then, the mention graph is processed with SPARQL-like rules using a specifically created mapping resource from NomBank/PropBank/FrameNet annotations to FrameBase concepts, producing a knowledge graph whose content is linked to DBpedia and organized around semantic frames, i.e., prototypical descriptions of events and situations. A single RDF/OWL representation is used where each triple is related to the mentions/tools it comes from. We implemented the approach in PIKES, an open source tool that combines two complementary SRL systems and provides a working online demo. We evaluated PIKES on a manually annotated gold standard, assessing precision/recall in (i) populating FrameBase ontology, and (ii) extracting semantic frames modeled after standard predicate models, for comparison with state-of-the-art tools for the Semantic Web. We also evaluated (iii) sampled precision and execution times on a large corpus of 110 K Wikipedia-like pages.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="2016jws" class="col-sm-12"> <div class="title"><a href="http://www.sciencedirect.com/science/article/pii/S1570826815001456" rel="external nofollow noopener" target="_blank">Building Event-Centric Knowledge Graphs from News</a></div> <div class="author"> Marco Rospocher, Marieke Erp, Piek Vossen, Antske Fokkens, Itziar Aldabe, German Rigau, Aitor Soroa, Thomas Ploeger, Tessel Bogaard </div> <div class="periodical"> <em>Web Semantics: Science, Services and Agents on the World Wide Web</em>, 2016 </div> <div class="periodical"> </div> </div> </div> </li> <li> <div class="row"> <div id="2019lre" class="col-sm-12"> <div class="title"><a href="https://link.springer.com/article/10.1007/s10579-018-9437-8" rel="external nofollow noopener" target="_blank">PreMOn: LODifing Linguistic Predicate Models</a></div> <div class="author"> Marco Rospocher, Francesco Corcoglioniti, Alessio Palmero Aprosio </div> <div class="periodical"> <em>Language Resources and Evaluation</em>, 2019 </div> <div class="periodical"> </div> </div> </div> </li> <li> <div class="row"> <div id="2019swj" class="col-sm-12"> <div class="title"><a href="https://content.iospress.com/articles/semantic-web/sw325" rel="external nofollow noopener" target="_blank">Boosting Document Retrieval with Knowledge Extraction and Linked Data</a></div> <div class="author"> Marco Rospocher, Francesco Corcoglioniti, Mauro Dragoni </div> <div class="periodical"> <em>Semantic Web - Interoperability, Usability, Applicability</em>, 2019 </div> <div class="periodical"> </div> <div class="abstract hidden"> <p>We present an approach for ontology population from natural language English texts that extracts RDF triples according to FrameBase, a Semantic Web ontology derived from FrameNet. Processing is decoupled in two independently-tunable phases. First, text is processed by several NLP tasks, including Semantic Role Labeling (SRL), whose results are integrated in an RDF graph of mentions, i.e., snippets of text denoting some entity/fact. Then, the mention graph is processed with SPARQL-like rules using a specifically created mapping resource from NomBank/PropBank/FrameNet annotations to FrameBase concepts, producing a knowledge graph whose content is linked to DBpedia and organized around semantic frames, i.e., prototypical descriptions of events and situations. A single RDF/OWL representation is used where each triple is related to the mentions/tools it comes from. We implemented the approach in PIKES, an open source tool that combines two complementary SRL systems and provides a working online demo. We evaluated PIKES on a manually annotated gold standard, assessing precision/recall in (i) populating FrameBase ontology, and (ii) extracting semantic frames modeled after standard predicate models, for comparison with state-of-the-art tools for the Semantic Web. We also evaluated (iii) sampled precision and execution times on a large corpus of 110 K Wikipedia-like pages.</p> </div> </div> </div> </li> </ol> </div> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> <div class="row" style="width:90%; margin:0 auto;"> <div class="col-md-4"> <a href="https://www.dlls.univr.it/" rel="external nofollow noopener" target="_blank"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/logo-univr-dills-480.webp 480w,/assets/img/logo-univr-dills-800.webp 800w,/assets/img/logo-univr-dills-1400.webp 1400w," sizes="480px" type="image/webp"> <img src="/assets/img/logo-univr-dills.png?358895eac87e7c47adc456f6ca490d6b" width="auto" height="95px" alt="Logos of the University of Verona and Department of Foreign Languages and Literatures" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </a> </div> <div class="col-md-3"> <a href="https://www.anvur.it/en/activities/departments/" rel="external nofollow noopener" target="_blank"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/logo-eccellenza_MUR_Colore-480.webp 480w,/assets/img/logo-eccellenza_MUR_Colore-800.webp 800w,/assets/img/logo-eccellenza_MUR_Colore-1400.webp 1400w," sizes="480px" type="image/webp"> <img src="/assets/img/logo-eccellenza_MUR_Colore.png?2840e7f47abdf682ac93486116823d30" width="auto" height="95px" alt="Logos of the University of Verona Department of Excellence 2023-2027" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </a> </div> <div class="col-md-5"> <a href="https://inclusivehumanities.eu/" rel="external nofollow noopener" target="_blank"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/logo-InclusiveHumanities_acolori_trasp-480.webp 480w,/assets/img/logo-InclusiveHumanities_acolori_trasp-800.webp 800w,/assets/img/logo-InclusiveHumanities_acolori_trasp-1400.webp 1400w," sizes="480px" type="image/webp"> <img src="/assets/img/logo-InclusiveHumanities_acolori_trasp.png?5d77375d6a6b6067c54928091430f9a9" width="auto" height="95px" alt="Logos of the Inclusive Humanities project" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </a> </div> </div> <br> © Copyright 2024 Digital Arena for Inclusive Humanities (DAIH). Last updated: December 19, 2024. <br> No cookies are used on this web-site. <a href="https://www.univr.it/privacy/" rel="external nofollow noopener" target="_blank">Privacy Policy</a>. <a href="/accessibility-stmt/">Accessibility Statement</a>. The site is <a href="https://docs.github.com/en/site-policy/privacy-policies/github-general-privacy-statement" rel="external nofollow noopener" target="_blank">hosted on GitHub</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?5d75c11f89cd96294bf5e6dd1ee1bb30"></script> <script defer src="/assets/js/common.js?fcfacfb8c6281f5e68d5a7d348186eb1"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>